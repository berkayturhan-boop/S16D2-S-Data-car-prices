{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Araba FiyatlarÄ± (Car Prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ¯ Bu challengeâ€™Ä±n amacÄ±, bir dataset hazÄ±rlamak ve ÅŸimdiye kadar Ã¶ÄŸrendiÄŸiniz bazÄ± feature selection tekniklerini uygulamaktÄ±r."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸš— Arabalarla ilgili bir veri setiyle Ã§alÄ±ÅŸÄ±yoruz ve bir arabanÄ±n pahalÄ± mÄ± yoksa ucuz mu olduÄŸunu tahmin etmek istiyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Data visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# SayÄ±sal bir Ã¶zelliÄŸin normal daÄŸÄ±lÄ±m gÃ¶sterip gÃ¶stermediÄŸini kontrol etme\n",
    "from statsmodels.graphics.gofplots import qqplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://d32aokrjazspmn.cloudfront.net/materials/ML_Cars_dataset.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ CSV dosyasÄ±nÄ± `df` adlÄ± bir veri Ã§erÃ§evesine yÃ¼kleyin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  aspiration enginelocation carwidth  curbweight enginetype cylindernumber  \\\n",
      "0        std          front     64.1        2548       dohc           four   \n",
      "1        std          front     64.1        2548       dohc           four   \n",
      "2        std          front     65.5        2823       ohcv            six   \n",
      "3        std          front      NaN        2337        ohc           four   \n",
      "4        std          front     66.4        2824        ohc           five   \n",
      "\n",
      "   stroke  peakrpm      price  \n",
      "0    2.68     5000  expensive  \n",
      "1    2.68     5000  expensive  \n",
      "2    3.47     5000  expensive  \n",
      "3    3.40     5500  expensive  \n",
      "4    3.40     5500  expensive  \n"
     ]
    }
   ],
   "source": [
    "# Data load\n",
    "df = pd.read_csv(url)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â„¹ï¸ Datasetâ€™in aÃ§Ä±klamasÄ± [burada](https://drive.google.com/file/d/1ADSyjWfRGYqdXwCCN4PPC7PjQeMZ-ap-/view?usp=sharing ) mevcuttur. Egzersiz boyunca buna mutlaka referans verin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Yinelenenler (Duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ Varsa, veri kÃ¼mesinden yinelenenleri kaldÄ±rÄ±n. â“\n",
    "\n",
    "*Veri Ã§erÃ§evesini `df`* Ã¼zerine yazÄ±n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aspiration</th>\n",
       "      <th>enginelocation</th>\n",
       "      <th>carwidth</th>\n",
       "      <th>curbweight</th>\n",
       "      <th>enginetype</th>\n",
       "      <th>cylindernumber</th>\n",
       "      <th>stroke</th>\n",
       "      <th>peakrpm</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>std</td>\n",
       "      <td>front</td>\n",
       "      <td>64.1</td>\n",
       "      <td>2548</td>\n",
       "      <td>dohc</td>\n",
       "      <td>four</td>\n",
       "      <td>2.680</td>\n",
       "      <td>5000</td>\n",
       "      <td>expensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>std</td>\n",
       "      <td>front</td>\n",
       "      <td>64.8</td>\n",
       "      <td>2395</td>\n",
       "      <td>ohc</td>\n",
       "      <td>four</td>\n",
       "      <td>2.800</td>\n",
       "      <td>5800</td>\n",
       "      <td>expensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>std</td>\n",
       "      <td>front</td>\n",
       "      <td>63.8</td>\n",
       "      <td>1876</td>\n",
       "      <td>ohc</td>\n",
       "      <td>four</td>\n",
       "      <td>3.230</td>\n",
       "      <td>5500</td>\n",
       "      <td>cheap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>std</td>\n",
       "      <td>front</td>\n",
       "      <td>63.8</td>\n",
       "      <td>1989</td>\n",
       "      <td>ohc</td>\n",
       "      <td>four</td>\n",
       "      <td>3.230</td>\n",
       "      <td>5500</td>\n",
       "      <td>cheap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>std</td>\n",
       "      <td>front</td>\n",
       "      <td>63.6</td>\n",
       "      <td>1909</td>\n",
       "      <td>ohc</td>\n",
       "      <td>four</td>\n",
       "      <td>3.110</td>\n",
       "      <td>5400</td>\n",
       "      <td>cheap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>std</td>\n",
       "      <td>front</td>\n",
       "      <td>65.7</td>\n",
       "      <td>2380</td>\n",
       "      <td>rotor</td>\n",
       "      <td>two</td>\n",
       "      <td>3.255</td>\n",
       "      <td>6000</td>\n",
       "      <td>expensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>std</td>\n",
       "      <td>front</td>\n",
       "      <td>66.5</td>\n",
       "      <td>2410</td>\n",
       "      <td>ohc</td>\n",
       "      <td>four</td>\n",
       "      <td>3.390</td>\n",
       "      <td>4800</td>\n",
       "      <td>cheap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>turbo</td>\n",
       "      <td>front</td>\n",
       "      <td>68.4</td>\n",
       "      <td>3252</td>\n",
       "      <td>l</td>\n",
       "      <td>four</td>\n",
       "      <td>3.520</td>\n",
       "      <td>4150</td>\n",
       "      <td>expensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>turbo</td>\n",
       "      <td>front</td>\n",
       "      <td>63.8</td>\n",
       "      <td>2128</td>\n",
       "      <td>ohc</td>\n",
       "      <td>four</td>\n",
       "      <td>3.390</td>\n",
       "      <td>5500</td>\n",
       "      <td>cheap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>std</td>\n",
       "      <td>front</td>\n",
       "      <td>63.8</td>\n",
       "      <td>1967</td>\n",
       "      <td>ohc</td>\n",
       "      <td>four</td>\n",
       "      <td>3.230</td>\n",
       "      <td>5500</td>\n",
       "      <td>cheap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>std</td>\n",
       "      <td>front</td>\n",
       "      <td>63.8</td>\n",
       "      <td>1989</td>\n",
       "      <td>ohc</td>\n",
       "      <td>four</td>\n",
       "      <td>3.230</td>\n",
       "      <td>5500</td>\n",
       "      <td>cheap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>std</td>\n",
       "      <td>front</td>\n",
       "      <td>64.6</td>\n",
       "      <td>2535</td>\n",
       "      <td>ohc</td>\n",
       "      <td>four</td>\n",
       "      <td>3.460</td>\n",
       "      <td>5000</td>\n",
       "      <td>cheap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>std</td>\n",
       "      <td>rear</td>\n",
       "      <td>65</td>\n",
       "      <td>2756</td>\n",
       "      <td>ohcf</td>\n",
       "      <td>six</td>\n",
       "      <td>2.900</td>\n",
       "      <td>5900</td>\n",
       "      <td>expensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>std</td>\n",
       "      <td>front</td>\n",
       "      <td>64.4</td>\n",
       "      <td>2275</td>\n",
       "      <td>ohc</td>\n",
       "      <td>four</td>\n",
       "      <td>3.350</td>\n",
       "      <td>4500</td>\n",
       "      <td>cheap</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    aspiration enginelocation carwidth  curbweight enginetype cylindernumber  \\\n",
       "1          std          front     64.1        2548       dohc           four   \n",
       "11         std          front     64.8        2395        ohc           four   \n",
       "22         std          front     63.8        1876        ohc           four   \n",
       "26         std          front     63.8        1989        ohc           four   \n",
       "45         std          front     63.6        1909        ohc           four   \n",
       "56         std          front     65.7        2380      rotor            two   \n",
       "62         std          front     66.5        2410        ohc           four   \n",
       "116      turbo          front     68.4        3252          l           four   \n",
       "119      turbo          front     63.8        2128        ohc           four   \n",
       "120        std          front     63.8        1967        ohc           four   \n",
       "121        std          front     63.8        1989        ohc           four   \n",
       "123        std          front     64.6        2535        ohc           four   \n",
       "127        std           rear       65        2756       ohcf            six   \n",
       "159        std          front     64.4        2275        ohc           four   \n",
       "\n",
       "     stroke  peakrpm      price  \n",
       "1     2.680     5000  expensive  \n",
       "11    2.800     5800  expensive  \n",
       "22    3.230     5500      cheap  \n",
       "26    3.230     5500      cheap  \n",
       "45    3.110     5400      cheap  \n",
       "56    3.255     6000  expensive  \n",
       "62    3.390     4800      cheap  \n",
       "116   3.520     4150  expensive  \n",
       "119   3.390     5500      cheap  \n",
       "120   3.230     5500      cheap  \n",
       "121   3.230     5500      cheap  \n",
       "123   3.460     5000      cheap  \n",
       "127   2.900     5900  expensive  \n",
       "159   3.350     4500      cheap  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates = df[df.duplicated()]\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2)  Eksik deÄŸerler (Missing values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ Eksik deÄŸerleri bulun ve bunlarÄ± ya `strategy = \"most frequent\"` (kategorik deÄŸiÅŸkenler iÃ§in) ya da `strategy = \"median\"` (sayÄ±sal deÄŸiÅŸkenler iÃ§in) kullanarak doldurun â“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspiration         0\n",
      "enginelocation    10\n",
      "carwidth           2\n",
      "curbweight         0\n",
      "enginetype         0\n",
      "cylindernumber     0\n",
      "stroke             0\n",
      "peakrpm            0\n",
      "price              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `carwidth`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary> ğŸ’¡ <i>Ä°pucu</i> </summary>\n",
    "    <br>\n",
    "    â„¹ï¸ <code>carwidth</code> sÃ¼tununda eksik deÄŸerler birden fazla ÅŸekilde temsil edilmektedir. BazÄ±larÄ± <code>np.nan</code>, bazÄ±larÄ± ise <code>*</code> olarak yer alÄ±r. Bunlar tespit edildikten sonra, eksik deÄŸerler verinin %30â€™undan daha azÄ±nÄ± oluÅŸturduÄŸu iÃ§in medyan deÄŸerle doldurulabilir.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspiration         0\n",
      "enginelocation    10\n",
      "carwidth           0\n",
      "curbweight         0\n",
      "enginetype         0\n",
      "cylindernumber     0\n",
      "stroke             0\n",
      "peakrpm            0\n",
      "price              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df['carwidth'] = pd.to_numeric(df['carwidth'], errors='coerce')\n",
    "\n",
    "median_carwidth = df['carwidth'].median()\n",
    "df['carwidth'] = df['carwidth'].fillna(median_carwidth)\n",
    "\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `enginelocation`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>ğŸ’¡ <i>Ä°pucu</i> </summary>\n",
    "    <br>\n",
    "    â„¹ï¸ <code>enginelocation</code> kategorik bir feature olduÄŸundan ve kategorilerin bÃ¼yÃ¼k Ã§oÄŸunluÄŸu <code>front</code> olduÄŸu iÃ§in, en sÄ±k gÃ¶rÃ¼len deÄŸerle doldurun.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspiration        0\n",
      "enginelocation    0\n",
      "carwidth          0\n",
      "curbweight        0\n",
      "enginetype        0\n",
      "cylindernumber    0\n",
      "stroke            0\n",
      "peakrpm           0\n",
      "price             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "mode_enginelocation = df['enginelocation'].mode()[0]\n",
    "df['enginelocation'] = df['enginelocation'].fillna(mode_enginelocation)\n",
    "\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ§ª **Kodunu test et**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.12.9, pytest-8.3.4, pluggy-1.5.0 -- /Users/berkayturhan/.pyenv/versions/workintech/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/berkayturhan/S16D2-S-Data-car-prices/tests\n",
      "plugins: dash-3.3.0, anyio-4.8.0, typeguard-4.4.2\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 2 items\n",
      "\n",
      "test_missing_values.py::TestMissing_values::test_carwidth \u001b[32mPASSED\u001b[0m\u001b[32m         [ 50%]\u001b[0m\n",
      "test_missing_values.py::TestMissing_values::test_engine_location \u001b[32mPASSED\u001b[0m\u001b[32m  [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 0.67s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "ğŸ’¯ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/missing_values.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed missing_values step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('missing_values',\n",
    "                         dataset = df)\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) SayÄ±sal Ã¶zelliklerin Ã¶lÃ§eklendirilmesi (Scaling the numerical features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 191 entries, 0 to 204\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   aspiration      191 non-null    object \n",
      " 1   enginelocation  191 non-null    object \n",
      " 2   carwidth        191 non-null    float64\n",
      " 3   curbweight      191 non-null    int64  \n",
      " 4   enginetype      191 non-null    object \n",
      " 5   cylindernumber  191 non-null    object \n",
      " 6   stroke          191 non-null    float64\n",
      " 7   peakrpm         191 non-null    int64  \n",
      " 8   price           191 non-null    object \n",
      "dtypes: float64(2), int64(2), object(5)\n",
      "memory usage: 14.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# HatÄ±rlatma olarak, DataFrame hakkÄ±nda bazÄ± bilgiler\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['carwidth', 'curbweight', 'stroke', 'peakrpm'], dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ve iÅŸte Ã¶lÃ§eklendirmemiz gereken veri kÃ¼mesinin sayÄ±sal Ã¶zellikleri\n",
    "numerical_features = df.select_dtypes(exclude=['object']).columns\n",
    "numerical_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Soru: SayÄ±sal featureâ€™larÄ±n Ã¶lÃ§eklenmesi** â“\n",
    "\n",
    "SayÄ±sal featureâ€™larÄ± aykÄ±rÄ± deÄŸerler (outliers) ve daÄŸÄ±lÄ±mlarÄ± aÃ§Ä±sÄ±ndan inceleyin ve duruma gÃ¶re aÅŸaÄŸÄ±daki yÃ¶ntemleri uygulayÄ±n:\n",
    "- Robust Scaler\n",
    "- Standard Scaler\n",
    "\n",
    "DÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸ deÄŸerlerle orijinal sÃ¼tunlarÄ± deÄŸiÅŸtirin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `peakrpm` , `carwidth` , & `stroke`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>ğŸ’¡ <i>Ä°pucu</i> </summary>\n",
    "\n",
    "    \n",
    "â„¹ï¸ <code>peakrpm</code>, <code>carwidth</code> ve <code>stroke</code> normal daÄŸÄ±lÄ±ma sahiptir ancak aynÄ± zamanda bazÄ± aykÄ±rÄ± deÄŸerler (outlier) iÃ§erir. Bu nedenle `RobustScaler()` kullanÄ±lmasÄ± tavsiye edilir.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    peakrpm  carwidth    stroke\n",
      "0 -0.142857 -0.518519 -2.033333\n",
      "2 -0.142857  0.000000  0.600000\n",
      "3  0.571429  0.000000  0.366667\n",
      "4  0.571429  0.333333  0.366667\n",
      "5  0.571429  0.296296  0.366667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "cols_to_scale = ['peakrpm', 'carwidth', 'stroke']\n",
    "\n",
    "for col in cols_to_scale:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "scaler = RobustScaler()\n",
    "\n",
    "df[cols_to_scale] = scaler.fit_transform(df[cols_to_scale])\n",
    "\n",
    "print(df[cols_to_scale].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `curbweight`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>ğŸ’¡ <i>Ä°pucu</i> </summary>\n",
    "    <br>\n",
    "    â„¹ï¸ <code>curbweight</code> normal bir daÄŸÄ±lÄ±ma sahiptir ve aykÄ±rÄ± deÄŸer (outlier) iÃ§ermez. Bu nedenle Standard Scaler ile Ã¶lÃ§eklenebilir.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   curbweight\n",
      "0   -0.048068\n",
      "2    0.476395\n",
      "3   -0.450474\n",
      "4    0.478302\n",
      "5   -0.126260\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "std_cols = ['curbweight']\n",
    "std_scaler = StandardScaler()\n",
    "\n",
    "df[std_cols] = std_scaler.fit_transform(df[std_cols])\n",
    "\n",
    "print(df[std_cols].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ§ª **Kodunu test et**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.12.9, pytest-8.3.4, pluggy-1.5.0 -- /Users/berkayturhan/.pyenv/versions/workintech/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/berkayturhan/S16D2-S-Data-car-prices/tests\n",
      "plugins: dash-3.3.0, anyio-4.8.0, typeguard-4.4.2\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 4 items\n",
      "\n",
      "test_scaling.py::TestScaling::test_carwidth \u001b[32mPASSED\u001b[0m\u001b[32m                       [ 25%]\u001b[0m\n",
      "test_scaling.py::TestScaling::test_curbweight \u001b[32mPASSED\u001b[0m\u001b[32m                     [ 50%]\u001b[0m\n",
      "test_scaling.py::TestScaling::test_peakrpm \u001b[32mPASSED\u001b[0m\u001b[32m                        [ 75%]\u001b[0m\n",
      "test_scaling.py::TestScaling::test_stroke \u001b[32mPASSED\u001b[0m\u001b[32m                         [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m4 passed\u001b[0m\u001b[32m in 0.38s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "ğŸ’¯ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/scaling.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed scaling step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('scaling',\n",
    "                         dataset = df\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) Kategorik Ã¶zelliklerin kodlanmasÄ± (Encoding the categorical features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Soru: Kategorik deÄŸiÅŸkenlerin encode edilmesi** â“\n",
    "\n",
    "ğŸ‘‡ Encode edilmesi gereken featureâ€™larÄ± inceleyin ve duruma gÃ¶re aÅŸaÄŸÄ±daki teknikleri uygulayÄ±n:\n",
    "\n",
    "- One-hot encoding\n",
    "- Manuel ordinal encoding\n",
    "\n",
    "DataFrame iÃ§inde, orijinal featureâ€™larÄ± encode edilmiÅŸ versiyonlarÄ±yla deÄŸiÅŸtirin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `aspiration` & `enginelocation`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>ğŸ’¡ <i>Ä°pucu</i> </summary>\n",
    "    <br>\n",
    "    â„¹ï¸ <code>aspiration</code> ve <code>enginelocation</code> ikili (binary) kategorik featureâ€™lardÄ±r.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspiration deÄŸerleri: ['std' 'turbo']\n",
      "Engine Location deÄŸerleri: ['front' 'rear']\n",
      "   aspiration  enginelocation\n",
      "0           0               0\n",
      "2           0               0\n",
      "3           0               0\n",
      "4           0               0\n",
      "5           0               0\n"
     ]
    }
   ],
   "source": [
    "print(\"Aspiration deÄŸerleri:\", df['aspiration'].unique())\n",
    "print(\"Engine Location deÄŸerleri:\", df['enginelocation'].unique())\n",
    "\n",
    "df['aspiration'] = df['aspiration'].map({'std': 0, 'turbo': 1})\n",
    "\n",
    "df['enginelocation'] = df['enginelocation'].map({'front': 0, 'rear': 1})\n",
    "\n",
    "print(df[['aspiration', 'enginelocation']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `enginetype`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>ğŸ’¡ <i>Ä°pucu</i> </summary>\n",
    "    <br>\n",
    "    â„¹ï¸ <code>enginetype</code> Ã§ok kategorili (multicategorical) bir featureâ€™dÄ±r ve One-hot encoding uygulanmalÄ±dÄ±r.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enginetype deÄŸerleri: ['dohc' 'ohcv' 'ohc' 'l' 'rotor' 'ohcf' 'dohcv']\n",
      "   aspiration  enginelocation  carwidth  curbweight cylindernumber    stroke  \\\n",
      "0           0               0 -0.518519   -0.048068           four -2.033333   \n",
      "2           0               0  0.000000    0.476395            six  0.600000   \n",
      "3           0               0  0.000000   -0.450474           four  0.366667   \n",
      "4           0               0  0.333333    0.478302           five  0.366667   \n",
      "5           0               0  0.296296   -0.126260           five  0.366667   \n",
      "\n",
      "    peakrpm      price  enginetype_dohc  enginetype_dohcv  enginetype_l  \\\n",
      "0 -0.142857  expensive                1                 0             0   \n",
      "2 -0.142857  expensive                0                 0             0   \n",
      "3  0.571429  expensive                0                 0             0   \n",
      "4  0.571429  expensive                0                 0             0   \n",
      "5  0.571429  expensive                0                 0             0   \n",
      "\n",
      "   enginetype_ohc  enginetype_ohcf  enginetype_ohcv  enginetype_rotor  \n",
      "0               0                0                0                 0  \n",
      "2               0                0                1                 0  \n",
      "3               1                0                0                 0  \n",
      "4               1                0                0                 0  \n",
      "5               1                0                0                 0  \n"
     ]
    }
   ],
   "source": [
    "print(\"Enginetype deÄŸerleri:\", df['enginetype'].unique())\n",
    "\n",
    "df = pd.get_dummies(df, columns=['enginetype'], prefix='enginetype', dtype=int)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(191, 15)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `cylindernumber`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>ğŸ’¡ Ä°pucu </summary>\n",
    "\n",
    "â„¹ï¸ <code>cylindernumber</code> sÄ±ralÄ± (ordinal) bir featureâ€™dÄ±r ve sayÄ±sal deÄŸerlere manuel olarak encode edilmelidir.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "cylinder_mapping = {\n",
    "    'two': 2,\n",
    "    'three': 3,\n",
    "    'four': 4,\n",
    "    'five': 5,\n",
    "    'six': 6,\n",
    "    'eight': 8,\n",
    "    'twelve': 12\n",
    "}\n",
    "\n",
    "df['cylindernumber'] = df['cylindernumber'].map(cylinder_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ ArtÄ±k `cylindernumber`â€™Ä± 2 ile 12 arasÄ±nda sayÄ±sal bir featureâ€™a dÃ¶nÃ¼ÅŸtÃ¼rdÃ¼ÄŸÃ¼nÃ¼ze gÃ¶re, bunu Ã¶lÃ§eklendirmeniz gerekiyor â“\n",
    "\n",
    "<br/>\n",
    "\n",
    "<details>\n",
    "    <summary>ğŸ’¡ Ä°pucu </summary>\n",
    "\n",
    "`cylindernumber`â€™Ä±n mevcut daÄŸÄ±lÄ±mÄ±na bakÄ±n ve kendinize ÅŸu sorularÄ± sorun:\n",
    "- Ã–lÃ§ekleme, bir featureâ€™Ä±n daÄŸÄ±lÄ±mÄ±nÄ± etkiler mi?\n",
    "- Bu featureâ€™Ä±n daÄŸÄ±lÄ±mÄ±na gÃ¶re en uygun Ã¶lÃ§ekleme yÃ¶ntemi hangisidir?\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cylindernumber\n",
      "0             0.0\n",
      "2             2.0\n",
      "3             0.0\n",
      "4             1.0\n",
      "5             1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler = RobustScaler()\n",
    "\n",
    "df[['cylindernumber']] = scaler.fit_transform(df[['cylindernumber']])\n",
    "\n",
    "print(df[['cylindernumber']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><i>Ã–lÃ§ekleme ve encoding iÅŸlemlerinden sonra DataFrameâ€™inizin nasÄ±l gÃ¶rÃ¼nmesi gerektiÄŸine dair bir ekran gÃ¶rÃ¼ntÃ¼sÃ¼ aÅŸaÄŸÄ±dadÄ±r</i></summary>\n",
    "    \n",
    "    \n",
    "<img src=\"https://wagon-public-datasets.s3.amazonaws.com/05-Machine-Learning/02-Prepare-the-dataset/car_price_after_scaling_and_encoding.png\">    \n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   aspiration  enginelocation  carwidth  curbweight  cylindernumber    stroke  \\\n",
      "0           0               0 -0.518519   -0.048068             0.0 -2.033333   \n",
      "2           0               0  0.000000    0.476395             2.0  0.600000   \n",
      "3           0               0  0.000000   -0.450474             0.0  0.366667   \n",
      "4           0               0  0.333333    0.478302             1.0  0.366667   \n",
      "5           0               0  0.296296   -0.126260             1.0  0.366667   \n",
      "\n",
      "    peakrpm      price  enginetype_dohc  enginetype_dohcv  enginetype_l  \\\n",
      "0 -0.142857  expensive                1                 0             0   \n",
      "2 -0.142857  expensive                0                 0             0   \n",
      "3  0.571429  expensive                0                 0             0   \n",
      "4  0.571429  expensive                0                 0             0   \n",
      "5  0.571429  expensive                0                 0             0   \n",
      "\n",
      "   enginetype_ohc  enginetype_ohcf  enginetype_ohcv  enginetype_rotor  \n",
      "0               0                0                0                 0  \n",
      "2               0                0                1                 0  \n",
      "3               1                0                0                 0  \n",
      "4               1                0                0                 0  \n",
      "5               1                0                0                 0  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `price`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ‘‡ Hedef `price`Ä± kodlayÄ±n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>ğŸ’¡ Ä°pucu </summary>\n",
    "    <br>\n",
    "    â„¹ï¸ <code>price</code> target deÄŸiÅŸkendir ve LabelEncoder ile encode edilmelidir.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "5    1\n",
      "Name: price, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "df['price'] = le.fit_transform(df['price'])\n",
    "\n",
    "print(df['price'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ§ª **Kodunu test et**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.12.9, pytest-8.3.4, pluggy-1.5.0 -- /Users/berkayturhan/.pyenv/versions/workintech/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/berkayturhan/S16D2-S-Data-car-prices/tests\n",
      "plugins: dash-3.3.0, anyio-4.8.0, typeguard-4.4.2\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 4 items\n",
      "\n",
      "test_encoding.py::TestEncoding::test_aspiration \u001b[32mPASSED\u001b[0m\u001b[32m                   [ 25%]\u001b[0m\n",
      "test_encoding.py::TestEncoding::test_enginelocation \u001b[32mPASSED\u001b[0m\u001b[32m               [ 50%]\u001b[0m\n",
      "test_encoding.py::TestEncoding::test_enginetype \u001b[32mPASSED\u001b[0m\u001b[32m                   [ 75%]\u001b[0m\n",
      "test_encoding.py::TestEncoding::test_price \u001b[32mPASSED\u001b[0m\u001b[32m                        [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m4 passed\u001b[0m\u001b[32m in 0.60s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "ğŸ’¯ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/encoding.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed encoding step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('encoding',\n",
    "                         dataset = df)\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5) Temel Modelleme (Base Modelling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ‘ Veri kÃ¼mesi Ã¶n iÅŸleme tabi tutuldu ve artÄ±k modele uyarlanmaya hazÄ±r. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Soru: Bir classification modelini ilk kez deÄŸerlendirme** â“\n",
    "\n",
    "Ã–n iÅŸlenmiÅŸ bu dataset Ã¼zerinde bir `LogisticRegression` modeli iÃ§in cross-validation Ã§alÄ±ÅŸtÄ±rÄ±n ve elde edilen skoru `base_model_score` adlÄ± deÄŸiÅŸkende saklayÄ±n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model Score (Accuracy): 0.8430499325236166\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X = df.drop(columns=['price'])\n",
    "\n",
    "y = df['price']\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "\n",
    "base_model_score = scores.mean()\n",
    "\n",
    "print(f\"Base Model Score (Accuracy): {base_model_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ§ª **Kodunu test et**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.12.9, pytest-8.3.4, pluggy-1.5.0 -- /Users/berkayturhan/.pyenv/versions/workintech/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/berkayturhan/S16D2-S-Data-car-prices/tests\n",
      "plugins: dash-3.3.0, anyio-4.8.0, typeguard-4.4.2\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 1 item\n",
      "\n",
      "test_base_model.py::TestBase_model::test_base_model_score \u001b[32mPASSED\u001b[0m\u001b[32m         [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.16s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "ğŸ’¯ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/base_model.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed base_model step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('base_model',\n",
    "                         score = base_model_score\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (6) Ã–zellik SeÃ§imi  (Feature Selection (with _Permutation Importance_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ‘©ğŸ»â€ğŸ« Bir featureâ€™Ä±n targetâ€™Ä± tahmin etmede gerÃ§ekten Ã¶nemli olup olmadÄ±ÄŸÄ±nÄ± tespit etmenin gÃ¼Ã§lÃ¼ bir yolu ÅŸudur:\n",
    "\n",
    "1. Bir model Ã§alÄ±ÅŸtÄ±rÄ±n ve skorunu Ã¶lÃ§Ã¼n  \n",
    "2. Bu featureâ€™Ä± karÄ±ÅŸtÄ±rÄ±n (shuffle edin), modeli tekrar Ã§alÄ±ÅŸtÄ±rÄ±n ve skoru tekrar Ã¶lÃ§Ã¼n  \n",
    "    - EÄŸer performans **belirgin ÅŸekilde dÃ¼ÅŸerse**, bu feature Ã¶nemlidir ve **Ã§Ä±karÄ±lmamalÄ±dÄ±r**\n",
    "    - EÄŸer performans **Ã§ok fazla dÃ¼ÅŸmezse**, bu feature **elenebilir**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Sorular** â“\n",
    "\n",
    "1. Modele en az bilgi katkÄ±sÄ± saÄŸlayan featureâ€™larÄ± tespit etmek iÃ§in feature permutation uygulayÄ±n.\n",
    "2. Model performansÄ±nÄ±n belirgin ÅŸekilde dÃ¼ÅŸmeye baÅŸladÄ±ÄŸÄ±nÄ± fark edene kadar zayÄ±f featureâ€™larÄ± datasetâ€™ten Ã§Ä±karÄ±n.\n",
    "3. Elde ettiÄŸiniz yeni gÃ¼Ã§lÃ¼ feature setâ€™i ile yeni bir modeli cross-validation ile deÄŸerlendirin ve skorunu `strong_model_score` adlÄ± deÄŸiÅŸkende saklayÄ±n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En Ã¶nemli Ã¶zellikler:\n",
      "              feature  importance\n",
      "3         curbweight    0.290576\n",
      "2           carwidth    0.114660\n",
      "5             stroke    0.029843\n",
      "11   enginetype_ohcf    0.017277\n",
      "10    enginetype_ohc    0.015183\n",
      "6            peakrpm    0.014136\n",
      "13  enginetype_rotor    0.011518\n",
      "4     cylindernumber    0.009948\n",
      "0         aspiration    0.009424\n",
      "7    enginetype_dohc    0.005236\n",
      "\n",
      "Toplam 14 Ã¶zellikten 7 tanesi seÃ§ildi.\n",
      "Strong Model Score: 0.874493927125506\n"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Modeli tÃ¼m veri kÃ¼mesi Ã¼zerinde eÄŸitiyoruz\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X, y)\n",
    "\n",
    "permutation_score = permutation_importance(model, X, y, n_repeats=10, random_state=42)\n",
    "\n",
    "# Ã–zellik Ã¶nemini alÄ±yoruz\n",
    "import pandas as pd\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': permutation_score.importances_mean\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "print(\"En Ã¶nemli Ã¶zellikler:\\n\", importance_df.head(10))\n",
    "\n",
    "# ZayÄ±f Ã¶zellikleri kaldÄ±rÄ±yoruz\n",
    "threshold = 0.01\n",
    "strong_features = importance_df[importance_df['importance'] > threshold]['feature'].tolist()\n",
    "\n",
    "print(f\"\\nToplam {len(X.columns)} Ã¶zellikten {len(strong_features)} tanesi seÃ§ildi.\")\n",
    "\n",
    "# Yeni gÃ¼Ã§lÃ¼ veri seti\n",
    "X_strong = X[strong_features]\n",
    "\n",
    "scores = cross_val_score(model, X_strong, y, cv=5)\n",
    "strong_model_score = scores.mean()\n",
    "\n",
    "print(f\"Strong Model Score: {strong_model_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ§ª **Kodunu test et**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.12.9, pytest-8.3.4, pluggy-1.5.0 -- /Users/berkayturhan/.pyenv/versions/workintech/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/berkayturhan/S16D2-S-Data-car-prices/tests\n",
      "plugins: dash-3.3.0, anyio-4.8.0, typeguard-4.4.2\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 1 item\n",
      "\n",
      "test_strong_model.py::TestStrong_model::test_strong_model_score \u001b[32mPASSED\u001b[0m\u001b[32m   [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.14s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "ğŸ’¯ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/strong_model.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed strong_model step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('strong_model',\n",
    "                         score = strong_model_score\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus -  Verilerinizi sÄ±nÄ±flandÄ±rma (Stratifying your data) âš–ï¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ’¡ Veriyi training ve testing olarak bÃ¶lerken, datasetâ€™imizdeki kategorik deÄŸiÅŸkenlerin oranÄ±na dikkat etmemiz gerekir â€” ister target `y`â€™nin sÄ±nÄ±flarÄ± olsun ister `X` iÃ§indeki kategorik bir feature olsun.\n",
    "\n",
    "AÅŸaÄŸÄ±da bir Ã¶rneÄŸe bakalÄ±m ğŸ‘‡\n",
    "\n",
    "â“ Orijinal `X` ve `y` verinizi sklearnâ€™in `train_test_split` fonksiyonunu kullanarak training ve testing olarak ayÄ±rÄ±n; karÅŸÄ±laÅŸtÄ±rÄ±labilir sonuÃ§lar elde etmek iÃ§in `random_state=1` ve `test_size=0.3` kullanÄ±n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Setindeki Oranlar:\n",
      " price\n",
      "1    0.503759\n",
      "0    0.496241\n",
      "Name: proportion, dtype: float64\n",
      "Test Setindeki Oranlar:\n",
      " price\n",
      "1    0.517241\n",
      "0    0.482759\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Verileri train ve test olarak ayÄ±rma\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_strong, y, test_size=0.3, random_state=1)\n",
    "\n",
    "print(\"Train Setindeki Oranlar:\\n\", y_train.value_counts(normalize=True))\n",
    "print(\"Test Setindeki Oranlar:\\n\", y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ Training datasetâ€™inizde ve testing datasetâ€™inizde `price` sÄ±nÄ±fÄ± **1** olan araÃ§larÄ±n oranÄ±nÄ± kontrol edin.\n",
    "\n",
    "> _Ham `df` iÃ§inde bu orana baktÄ±ÄŸÄ±nÄ±zda, yaklaÅŸÄ±k **%50 / %50** olmasÄ± gerekir._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train setinde price sÄ±nÄ±fÄ± 1 oranÄ±: 0.5037593984962406\n",
      "Test setinde price sÄ±nÄ±fÄ± 1 oranÄ±: 0.5172413793103449\n"
     ]
    }
   ],
   "source": [
    "# Training datasetâ€™inizde ve testing datasetâ€™inizde `price` sÄ±nÄ±fÄ± **1** olan araÃ§larÄ±n oranÄ±nÄ± kontrol edelim.\n",
    "print(\"Train setinde price sÄ±nÄ±fÄ± 1 oranÄ±:\", (y_train == 1).mean())\n",
    "print(\"Test setinde price sÄ±nÄ±fÄ± 1 oranÄ±:\", (y_test == 1).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â˜ï¸ HÃ¢lÃ¢ yaklaÅŸÄ±k olarak **%50 / %50** civarÄ±nda olmalÄ±.\n",
    "\n",
    "***Peki random stateâ€™i deÄŸiÅŸtirirsek ne olur?***\n",
    "\n",
    "â“ `random_state` deÄŸerlerini **1â€™den 10â€™a** kadar dÃ¶ngÃ¼ye alÄ±n ve her seferinde training ve testing datasetâ€™lerindeki `price` sÄ±nÄ±fÄ± **1** olan araÃ§larÄ±n oranÄ±nÄ± hesaplayÄ±n. â“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random State 1: Train price=1 oranÄ±: 0.5038, Test price=1 oranÄ±: 0.5172\n",
      "Random State 2: Train price=1 oranÄ±: 0.4812, Test price=1 oranÄ±: 0.5690\n",
      "Random State 3: Train price=1 oranÄ±: 0.5038, Test price=1 oranÄ±: 0.5172\n",
      "Random State 4: Train price=1 oranÄ±: 0.5338, Test price=1 oranÄ±: 0.4483\n",
      "Random State 5: Train price=1 oranÄ±: 0.5338, Test price=1 oranÄ±: 0.4483\n",
      "Random State 6: Train price=1 oranÄ±: 0.4962, Test price=1 oranÄ±: 0.5345\n",
      "Random State 7: Train price=1 oranÄ±: 0.5338, Test price=1 oranÄ±: 0.4483\n",
      "Random State 8: Train price=1 oranÄ±: 0.4887, Test price=1 oranÄ±: 0.5517\n",
      "Random State 9: Train price=1 oranÄ±: 0.5789, Test price=1 oranÄ±: 0.3448\n",
      "Random State 10: Train price=1 oranÄ±: 0.4887, Test price=1 oranÄ±: 0.5517\n"
     ]
    }
   ],
   "source": [
    "for random_state in range(1, 11):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_strong, y, test_size=0.3, random_state=random_state)\n",
    "    train_ratio = (y_train == 1).mean()\n",
    "    test_ratio = (y_test == 1).mean()\n",
    "    print(f\"Random State {random_state}: Train price=1 oranÄ±: {train_ratio:.4f}, Test price=1 oranÄ±: {test_ratio:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Her seferinde oranlarÄ±n deÄŸiÅŸtiÄŸini, hatta bazen oldukÃ§a ciddi ÅŸekilde deÄŸiÅŸtiÄŸini gÃ¶zlemleyeceksiniz ğŸ˜±! Bu durum model performansÄ±nÄ± etkileyebilir.\n",
    "\n",
    "â“ `train_test_split(random_state=1)` kullanÄ±larak eÄŸitilen bir Logistic Regression modelinin test skorunu,  \n",
    "`random_state=9` kullanÄ±larak eÄŸitilen modelin test skoru ile karÅŸÄ±laÅŸtÄ±rÄ±n â“\n",
    "\n",
    "EÄŸitimi training data Ã¼zerinde yapmayÄ± ve skoru testing data Ã¼zerinde hesaplamayÄ± unutmayÄ±n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score with random_state=1: 0.9137931034482759\n",
      "Model Score with random_state=9: 0.7931034482758621\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_strong, y, test_size=0.3, random_state=1)\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "score_1 = model.score(X_test, y_test)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_strong, y, test_size=0.3, random_state=9)\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "score_9 = model.score(X_test, y_test)\n",
    "\n",
    "print(f\"Model Score with random_state=1: {score_1}\")\n",
    "print(f\"Model Score with random_state=9: {score_9}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ‘€ `random_state=9` ile Ã§ok daha dÃ¼ÅŸÃ¼k bir skor gÃ¶rmelisiniz; Ã§Ã¼nkÃ¼ bu test setindeki sÄ±nÄ±f **1** araÃ§larÄ±n oranÄ± %34.5 iken, training setinde bu oran %57.9â€™a, hatta orijinal datasetâ€™te yaklaÅŸÄ±k %50â€™ye yakÄ±ndÄ±r.\n",
    "\n",
    "Bu durum oldukÃ§a Ã¶nemlidir; Ã§Ã¼nkÃ¼ datasetâ€™te oluÅŸan bu **rastlantÄ±sal dengesizlik**, yalnÄ±zca model performansÄ±nÄ± dÃ¼ÅŸÃ¼rmekle kalmaz, aynÄ± zamanda eÄŸitim veya deÄŸerlendirme sÄ±rasÄ±nda â€œgerÃ§ekliÄŸiâ€ de bozabilir ğŸ§"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Peki bu sorunu nasÄ±l Ã§Ã¶zebiliriz? Tren seti ve test seti arasÄ±nda sÄ±nÄ±flarÄ±n daÄŸÄ±lÄ±mÄ±nÄ± nasÄ±l aynÄ± tutabiliriz? ğŸ”§***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ Neyse ki sklearnâ€™de, estimator (yani model) bir classifier olduÄŸunda ve target bir sÄ±nÄ±f olduÄŸunda, bu durum `cross_validate` tarafÄ±ndan otomatik olarak ele alÄ±nÄ±r. ğŸ“š [**sklearn.model_selection.cross_validate**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html) dokÃ¼mantasyonunda `cv` parametresini inceleyin.\n",
    "\n",
    "Ã‡Ã¶zÃ¼m, aÅŸaÄŸÄ±dakini kullanmaktÄ±r:\n",
    "\n",
    "> ğŸ“š [**Stratification (Katmanlama)**](https://scikit-learn.org/stable/modules/cross_validation.html#stratification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hedefin tabakalaÅŸmasÄ± (Stratification of the target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ’¡ ***Stratification*** tekniÄŸini `train_test_split` iÃ§inde de kullanabiliriz.\n",
    "\n",
    "â“ Bu kez **1â€™den 10â€™a** kadar olan `random_state` dÃ¶ngÃ¼sÃ¼nÃ¼ tekrar Ã§alÄ±ÅŸtÄ±rÄ±n, ancak bu sefer holdout yÃ¶ntemine ***`stratify=y`*** parametresini de ekleyin. â“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random State 1: Train price=1 oranÄ±: 0.5113, Test price=1 oranÄ±: 0.5000\n",
      "Random State 2: Train price=1 oranÄ±: 0.5113, Test price=1 oranÄ±: 0.5000\n",
      "Random State 3: Train price=1 oranÄ±: 0.5113, Test price=1 oranÄ±: 0.5000\n",
      "Random State 4: Train price=1 oranÄ±: 0.5113, Test price=1 oranÄ±: 0.5000\n",
      "Random State 5: Train price=1 oranÄ±: 0.5113, Test price=1 oranÄ±: 0.5000\n",
      "Random State 6: Train price=1 oranÄ±: 0.5113, Test price=1 oranÄ±: 0.5000\n",
      "Random State 7: Train price=1 oranÄ±: 0.5113, Test price=1 oranÄ±: 0.5000\n",
      "Random State 8: Train price=1 oranÄ±: 0.5113, Test price=1 oranÄ±: 0.5000\n",
      "Random State 9: Train price=1 oranÄ±: 0.5113, Test price=1 oranÄ±: 0.5000\n",
      "Random State 10: Train price=1 oranÄ±: 0.5113, Test price=1 oranÄ±: 0.5000\n"
     ]
    }
   ],
   "source": [
    "for random_state in range(1, 11):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_strong, y, test_size=0.3, random_state=random_state, stratify=y)\n",
    "    train_ratio = (y_train == 1).mean()\n",
    "    test_ratio = (y_test == 1).mean()\n",
    "    print(f\"Random State {random_state}: Train price=1 oranÄ±: {train_ratio:.4f}, Test price=1 oranÄ±: {test_ratio:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ‘€ Random state deÄŸiÅŸse bile, training ve testing verilerindeki sÄ±nÄ±f oranlarÄ±, orijinal `y` iÃ§indeki oranlarla aynÄ± tutulur. Ä°ÅŸte _stratification_ (katmanlama) tam olarak budur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train_test_split` fonksiyonunu `stratify` parametresiyle kullandÄ±ÄŸÄ±mÄ±zda, training ve testing verileri arasÄ±nda **bir featureâ€™Ä±n oranlarÄ±nÄ± da koruyabiliriz**. Bu, Ã¶zellikle aÅŸaÄŸÄ±daki durumlarda son derece Ã¶nemlidir:\n",
    "\n",
    "- Churn tahmininde erkek ve kadÄ±n mÃ¼ÅŸteri oranlarÄ±nÄ± korumak ğŸ™‹â€â™‚ï¸ ğŸ™‹\n",
    "- Ev fiyatlarÄ±nÄ± tahmin ederken bÃ¼yÃ¼k ve kÃ¼Ã§Ã¼k evlerin oranlarÄ±nÄ± korumak ğŸ  ğŸ°\n",
    "- Bir sonraki Ã¼rÃ¼nÃ¼ Ã¶nerirken 1â€“5 arasÄ± review score daÄŸÄ±lÄ±mÄ±nÄ± (multiclass!) korumak ğŸ›ï¸\n",
    "- vb.\n",
    "\n",
    "Ã–rneÄŸin, bizim datasetâ€™imizde `aspiration` featureâ€™Ä±nÄ±n training ve testing verilerinde aynÄ± oranda kalmasÄ±nÄ± istiyorsak, ÅŸu ÅŸekilde yazabiliriz:\n",
    "\n",
    "`train_test_split(X, y, test_size=0.3, stratify=X.aspiration)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GÃ¶rdÃ¼ÄŸÃ¼mÃ¼z gibi, **`cross_validate` [target deÄŸiÅŸkeni otomatik olarak stratify edebilir](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#:~:text=For%20int/None%20inputs%2C%20if%20the%20estimator%20is%20a%20classifier%20and%20y%20is%20either%20binary%20or%20multiclass%2C%20StratifiedKFold%20is%20used.)**, ancak **featureâ€™lar iÃ§in bunu yapmaz** ğŸ¤” Bunun iÃ§in biraz ekstra Ã§alÄ±ÅŸmaya ihtiyacÄ±mÄ±z var.\n",
    "\n",
    "Bunun iÃ§in `StratifiedKFold` kullanmamÄ±z gerekiyor ğŸ”¬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TabakalaÅŸma (Stratification - generalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ“š [**StratifiedKFold**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html), veriyi `K` parÃ§aya bÃ¶lerken belirli sÃ¼tunlar (feature veya target) Ã¼zerinden stratification yapmamÄ±za olanak tanÄ±r.\n",
    "\n",
    "Bu sayede, ilgilendiÄŸimiz kategorik featureâ€™larÄ±n oranlarÄ±nÄ± koruyarak manuel bir cross-validation yapabiliriz â€” bunu ikili (binary) `aspiration` featureâ€™Ä± ile deneyelim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8585695006747638"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Veriyi 5 foldâ€™a bÃ¶lecek bir stratified k-fold oluÅŸturma\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "scores = []\n",
    "\n",
    "# .split() metodu bir iterator oluÅŸturur; 'X.aspiration' stratify edeceÄŸimiz featureâ€™dÄ±r\n",
    "for train_indices, test_indices in skf.split(X, X.aspiration):\n",
    "\n",
    "    # 'train_indices' ve 'test_indices', orantÄ±lÄ± bÃ¶lÃ¼nmeler Ã¼reten indeks listeleridir\n",
    "    X_train, X_test = X.iloc[train_indices], X.iloc[test_indices]\n",
    "    y_train, y_test = y.iloc[train_indices], y.iloc[test_indices]\n",
    "\n",
    "    # modeli baÅŸlatma ve eÄŸitme\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # en sonunda 5 foldâ€™un ortalamasÄ±nÄ± almak iÃ§in skoru listeye ekleme\n",
    "    scores.append(model.score(X_test, y_test))\n",
    "\n",
    "np.array(scores).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ“š [**StratifiedKFold**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html), veriyi `K` parÃ§aya bÃ¶lerken belirli sÃ¼tunlar (feature veya target) Ã¼zerinden stratification yapmamÄ±za olanak tanÄ±r.\n",
    "\n",
    "Bu sayede, ilgilendiÄŸimiz kategorik featureâ€™larÄ±n oranlarÄ±nÄ± koruyarak manuel bir cross-validation yapabiliriz â€” bunu ikili (binary) `aspiration` featureâ€™Ä± ile deneyelim:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ Tebrikler! TÃ¼m veri setini hazÄ±rladÄ±nÄ±z, Ã¶zellik seÃ§imi yaptÄ±nÄ±z ve hatta tabakalaÅŸma hakkÄ±nda bilgi edindiniz ğŸ’ª.\n",
    "\n",
    "ğŸ’¾ Not defterinizi git add/commit/push yapmayÄ± unutmayÄ±n...\n",
    "\n",
    "ğŸš€ ... ve bir sonraki challenge'a geÃ§in!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workintech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
